"""
æ‰¹é‡æ¸…æ´—è„šæœ¬ - ä»Ž Excel è¯»å–è´¦æˆ·æ•°æ®ï¼Œè°ƒç”¨ Gemini API æ¸…æ´—ï¼Œè¾“å‡ºåˆ°æ–° Excel
"""
import sys
import io

# ä¿®å¤ Windows ç»ˆç«¯ç¼–ç é—®é¢˜ï¼ˆæ”¯æŒ emoji å’Œä¸­æ–‡ï¼‰
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import asyncio
import time
import pandas as pd
from pathlib import Path
from datetime import datetime
from tqdm.asyncio import tqdm_asyncio

import config
from gemini_service import get_gemini_service
from preprocessor import normalize_separator


# ============ é…ç½®åŒºåŸŸ ============
INPUT_FILE = r"D:\dev\test-doc\account-cleaner\æµ‹è¯•é›†.xlsx"  # è¾“å…¥æ–‡ä»¶è·¯å¾„
INPUT_COLUMN = "A"  # åŽŸå§‹è´¦æˆ·æ‰€åœ¨åˆ—ï¼ˆAåˆ— = ç¬¬0åˆ—ï¼‰
MAX_ROWS = None  # æœ€å¤šå¤„ç†è¡Œæ•°ï¼ˆè®¾ä¸º None å¤„ç†å…¨éƒ¨ï¼‰
# =================================


async def process_batch(gemini_service, batch: list, batch_index: int) -> tuple:
    """å¤„ç†å•ä¸ªæ‰¹æ¬¡ï¼Œè¿”å›ž (batch_index, batch, results)"""
    try:
        results = await gemini_service.clean_batch(batch)
        return (batch_index, batch, results, None)
    except Exception as e:
        return (batch_index, batch, None, str(e))


async def main():
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    print("=" * 50)
    print("è´¦æˆ·æ•°æ®æ‰¹é‡æ¸…æ´—å·¥å…·")
    print("=" * 50)
    print(f"\nâš™ï¸  é…ç½®: å¹¶å‘æ•°={config.MAX_CONCURRENT_REQUESTS}, æ‰¹æ¬¡å¤§å°={config.BATCH_SIZE}, æ¨¡åž‹={config.GEMINI_MODEL}")
    
    # 1. è¯»å– Excel æ–‡ä»¶
    print(f"\nðŸ“‚ è¯»å–æ–‡ä»¶: {INPUT_FILE}")
    df = pd.read_excel(INPUT_FILE, header=None)
    
    # èŽ·å– A åˆ—æ•°æ®ï¼ˆç¬¬ 0 åˆ—ï¼‰
    col_index = ord(INPUT_COLUMN.upper()) - ord('A')
    accounts = df.iloc[:, col_index].dropna().astype(str).tolist()
    
    # è·³è¿‡è¡¨å¤´è¡Œï¼ˆå¦‚æžœç¬¬ä¸€è¡Œçœ‹èµ·æ¥æ˜¯è¡¨å¤´ï¼‰
    if accounts and accounts[0] in ["è´¦æˆ·", "è´¦æˆ·å", "åŽŸå§‹è´¦æˆ·", "account"]:
        print(f"âš ï¸  æ£€æµ‹åˆ°è¡¨å¤´è¡Œ '{accounts[0]}'ï¼Œå·²è·³è¿‡")
        accounts = accounts[1:]
    
    # è¿‡æ»¤æŽ‰æ˜Žæ˜¾ä¸æ˜¯è´¦æˆ·æ•°æ®çš„è¡Œï¼ˆå¤ªçŸ­æˆ–ä¸åŒ…å«åˆ†éš”ç¬¦ï¼‰
    original_count = len(accounts)
    accounts = [acc for acc in accounts if len(acc) > 5 and ("-" in acc or "_" in acc)]
    if len(accounts) < original_count:
        print(f"âš ï¸  è¿‡æ»¤æŽ‰ {original_count - len(accounts)} æ¡æ— æ•ˆæ•°æ®")
    
    # é™åˆ¶è¡Œæ•°
    if MAX_ROWS:
        accounts = accounts[:MAX_ROWS]
    
    print(f"ðŸ“Š å…±è¯»å– {len(accounts)} æ¡è´¦æˆ·æ•°æ®")
    
    # 2. é¢„å¤„ç†
    print("\nðŸ”§ é¢„å¤„ç†ä¸­...")
    accounts = [normalize_separator(acc) for acc in accounts]
    
    # 3. è°ƒç”¨ Gemini API æ‰¹é‡æ¸…æ´—ï¼ˆasyncio.gather å¹¶å‘æ¨¡å¼ï¼‰
    print(f"\nðŸš€ å¼€å§‹è°ƒç”¨ Gemini APIï¼ˆæ‰¹æ¬¡å¤§å°: {config.BATCH_SIZE}ï¼Œå¹¶å‘æ•°: {config.MAX_CONCURRENT_REQUESTS}ï¼‰")
    gemini_service = get_gemini_service()
    
    # åˆ†æ‰¹å¤„ç†
    batches = [accounts[i:i+config.BATCH_SIZE] for i in range(0, len(accounts), config.BATCH_SIZE)]
    print(f"ðŸ“¦ å…± {len(batches)} ä¸ªæ‰¹æ¬¡")
    
    # åˆ›å»ºæ‰€æœ‰å¹¶å‘ä»»åŠ¡
    tasks = [
        process_batch(gemini_service, batch, i)
        for i, batch in enumerate(batches)
    ]
    
    # ä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œï¼Œä¿¡å·é‡åœ¨ gemini_service ä¸­æŽ§åˆ¶å¹¶å‘æ•°
    batch_results = await tqdm_asyncio.gather(*tasks, desc="å¤„ç†è¿›åº¦")
    
    # æŒ‰åŽŸå§‹é¡ºåºæŽ’åºç»“æžœ
    batch_results = sorted(batch_results, key=lambda x: x[0])
    
    # æ•´ç†ç»“æžœ
    all_results = []
    failed_accounts = []
    
    for batch_index, batch, results, error in batch_results:
        if error:
            print(f"\nâŒ æ‰¹æ¬¡ {batch_index + 1} å¤„ç†å¤±è´¥: {error}")
            for acc in batch:
                failed_accounts.append(acc)
                all_results.append({"åŽŸå§‹è´¦æˆ·å": acc})
        else:
            for acc, result in zip(batch, results):
                if result:
                    result["åŽŸå§‹è´¦æˆ·å"] = acc
                    all_results.append(result)
                else:
                    failed_accounts.append(acc)
                    all_results.append({"åŽŸå§‹è´¦æˆ·å": acc})
    
    # 4. è¾“å‡ºåˆ° Excel
    print(f"\nâœ… å¤„ç†å®Œæˆï¼æˆåŠŸ: {len(all_results) - len(failed_accounts)}, å¤±è´¥: {len(failed_accounts)}")
    
    # åˆ›å»º DataFrame
    output_df = pd.DataFrame(all_results)
    
    # è°ƒæ•´åˆ—é¡ºåº
    columns_order = ["åŽŸå§‹è´¦æˆ·å", "åˆ†é”€è‡ªäº§", "ä¸Šå‰§æ—¥æœŸ", "åç§°", "ç›ˆåˆ©æ–¹å¼", "æŠ•æµäºº", "ç±»åž‹", "ä¸»ä½“"]
    for col in columns_order:
        if col not in output_df.columns:
            output_df[col] = None
    output_df = output_df[columns_order]
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = Path(INPUT_FILE).parent / f"æ¸…æ´—ç»“æžœ_{timestamp}.xlsx"
    
    output_df.to_excel(output_file, index=False)
    print(f"\nðŸ“ ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    
    # è¾“å‡ºå¤±è´¥åˆ—è¡¨
    if failed_accounts:
        failed_file = Path(INPUT_FILE).parent / f"å¤±è´¥è®°å½•_{timestamp}.txt"
        with open(failed_file, "w", encoding="utf-8") as f:
            f.write("\n".join(failed_accounts))
        print(f"âš ï¸ å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_file}")
    
    # è¾“å‡ºæ€»è€—æ—¶
    total_time = time.time() - start_time
    minutes = int(total_time // 60)
    seconds = total_time % 60
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {minutes}åˆ†{seconds:.1f}ç§’")
    print(f"ðŸ“ˆ å¤„ç†é€Ÿåº¦: {len(accounts) / total_time:.1f} æ¡/ç§’")


if __name__ == "__main__":
    asyncio.run(main())
